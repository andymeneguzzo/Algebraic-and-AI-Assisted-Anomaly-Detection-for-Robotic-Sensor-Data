{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3109ae2",
   "metadata": {},
   "source": [
    "# Algebraic and AI-Assisted Anomaly Detection for Robotic Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2218a2bf",
   "metadata": {},
   "source": [
    "- Load ../results/gemini_summary.json file\n",
    "- Call Gemini 2.0 flash with a prompt\n",
    "- Output AI report with\n",
    "    - hypothesis\n",
    "    - best detectors\n",
    "    - cross-sensor insights\n",
    "    - industrial relevance\n",
    "    - numerical patterns\n",
    "    - final summary\n",
    "- Save JSON output as /ai_report/report.json \n",
    "- Save readable/printable output as /ai_report/report.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cbdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Datasets in summary: ['lp1', 'lp2', 'lp3', 'lp4', 'lp5']\n",
      "[INFO] API_KEY found\n",
      "[INFO] Prompt saved → ../ai_report/gemini_prompt.json\n",
      "[INFO] Raw Gemini output saved → ../ai_report/gemini_raw.txt\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Imports & setup ---\n",
    "import os, json, textwrap, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import dotenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Optional install if google-generativeai is not present\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-generativeai\"])\n",
    "    import google.generativeai as genai\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# --- 2) Paths ---\n",
    "RESULTS_PATH = Path(\"../results\")\n",
    "AI_REPORT_PATH = Path(\"../ai_report\")\n",
    "AI_REPORT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "SUMMARY_JSON = RESULTS_PATH / \"gemini_summary.json\"\n",
    "RAW_TXT_PATH = AI_REPORT_PATH / \"gemini_raw.txt\"\n",
    "PROMPT_PATH = AI_REPORT_PATH / \"gemini_prompt.json\"\n",
    "REPORT_JSON_PATH = AI_REPORT_PATH / \"report.json\"\n",
    "REPORT_MD_PATH = AI_REPORT_PATH / \"report.md\"\n",
    "\n",
    "assert SUMMARY_JSON.exists(), f\"Missing {SUMMARY_JSON}. Run 05_model_comparison.ipynb first.\"\n",
    "\n",
    "# --- 3) Load summary & basic checks ---\n",
    "with open(SUMMARY_JSON, \"r\") as f:\n",
    "    project_summary = json.load(f)\n",
    "\n",
    "datasets = list(project_summary.keys())\n",
    "print(f\"[INFO] Datasets in summary: {datasets}\")\n",
    "\n",
    "\"\"\"Gemini 2.0flash config\"\"\"\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "if not API_KEY:\n",
    "    print(\"[WARNING] GEMINI_API_KEY not set in environment. Set it to enable API calls.\")\n",
    "if API_KEY:\n",
    "    print(f\"[INFO] API_KEY found\")\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "MODEL_NAME = \"gemini-2.0-flash\"\n",
    "GEN_CFG = dict(\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    max_output_tokens=3500,\n",
    ")\n",
    "\n",
    "\n",
    "\"\"\"Prompt\"\"\"\n",
    "SYSTEM_BRIEF = \"\"\"\n",
    "You are an expert AI Data Scientist specializing in anomaly detection for robotics time-series and multi-sensor data.\n",
    "You will analyze method metrics and correlations and produce a precise, structured report.\n",
    "Keep claims grounded in the provided numbers.\n",
    "\"\"\"\n",
    "\n",
    "# Clear, JSON-first contract so we can parse the output.\n",
    "JSON_SPEC = {\n",
    "  \"schema_version\": \"1.0\",\n",
    "  \"project_title\": \"Algebraic and AI-Assisted Anomaly Detection for Robotic Sensor Data\",\n",
    "  \"per_dataset\": {\n",
    "    \"<dataset_name>\": {\n",
    "      \"best_detectors\": [\n",
    "        {\"method\": \"<name>\", \"reason\": \"<short reason>\", \"supporting_numbers\": {\"mean\": 0.0, \"std\": 0.0, \"corr_to_others\": {\"PCA_Q\": 0.0}}}\n",
    "      ],\n",
    "      \"hypothesis\": [\"<concise, numbered hypotheses about root causes>\"],\n",
    "      \"numerical_patterns\": [\"<specific quantitative patterns or thresholds seen>\"],\n",
    "      \"notes\": \"<optional short note>\"\n",
    "    }\n",
    "  },\n",
    "  \"cross_sensor_insights\": [\"<patterns across datasets/sensors>\"],\n",
    "  \"industrial_relevance_insights\": [\"<why this matters in robotics / predictive maintenance>\"],\n",
    "  \"general_final_summary\": \"<tight executive summary for a technical manager>\"\n",
    "}\n",
    "\n",
    "def build_prompt(data: dict) -> str:\n",
    "    # Reduce noise: keep only what’s needed\n",
    "    reduced = {}\n",
    "    for ds, obj in data.items():\n",
    "        keep = {\n",
    "            \"mean_scores\": obj.get(\"mean_scores\", {}),\n",
    "            \"std_scores\": obj.get(\"std_scores\", {}),\n",
    "            \"method_correlations\": obj.get(\"method_correlations\", {}),\n",
    "        }\n",
    "        reduced[ds] = keep\n",
    "\n",
    "    instructions = {\n",
    "        \"task\": \"Analyze anomaly detector results and produce a structured JSON following the JSON_SPEC exactly.\",\n",
    "        \"requirements\": [\n",
    "            \"Pick 'best_detectors' per dataset: justify with numbers and correlations.\",\n",
    "            \"Generate 2–4 concise, testable 'hypothesis' per dataset.\",\n",
    "            \"List 2–5 'numerical_patterns' per dataset (thresholds, rank orders, surprising values).\",\n",
    "            \"Provide 3–6 'cross_sensor_insights' across datasets.\",\n",
    "            \"Provide 3–6 'industrial_relevance_insights' connecting patterns to maintenance decisions.\",\n",
    "            \"Finish with a single-paragraph 'general_final_summary' (executive tone).\",\n",
    "            \"Do not fabricate numbers. Use the provided means/stds/correlations.\",\n",
    "            \"If methods are missing for a dataset, acknowledge briefly.\"\n",
    "        ],\n",
    "        \"json_contract\": JSON_SPEC\n",
    "    }\n",
    "\n",
    "    prompt = {\n",
    "        \"system_brief\": SYSTEM_BRIEF.strip(),\n",
    "        \"instructions\": instructions,\n",
    "        \"data\": reduced\n",
    "    }\n",
    "    return json.dumps(prompt, indent=2)\n",
    "USER_PROMPT = build_prompt(project_summary)\n",
    "\n",
    "# Save prompt\n",
    "with open(PROMPT_PATH, \"w\") as f:\n",
    "    f.write(USER_PROMPT)\n",
    "print(f\"[INFO] Prompt saved → {PROMPT_PATH}\")\n",
    "\n",
    "\n",
    "\"\"\"Call Gemini 2.0 flash model\"\"\"\n",
    "def call_gemini(prompt_text: str, model_name: str = MODEL_NAME, cfg: dict = GEN_CFG, retries: int = 3, backoff: float = 2.0) -> str:\n",
    "    if not API_KEY:\n",
    "        return \"[ERROR] GEMINI_API_KEY missing. Skipping API call.\"\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "    last_err = None\n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            resp = model.generate_content(prompt_text, generation_config=cfg)\n",
    "            if hasattr(resp, \"text\") and resp.text:\n",
    "                return resp.text\n",
    "            # Some SDKs return candidates list\n",
    "            if hasattr(resp, \"candidates\") and resp.candidates:\n",
    "                return resp.candidates[0].content.parts[0].text\n",
    "            return str(resp)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[WARNING] Gemini call failed (attempt {attempt}/{retries}): {e}\")\n",
    "            time.sleep(backoff * attempt)\n",
    "    return f\"[ERROR] Gemini call failed after {retries} attempts: {last_err}\"\n",
    "\n",
    "\n",
    "raw_output = call_gemini(USER_PROMPT)\n",
    "with open(RAW_TXT_PATH, \"w\") as f:\n",
    "    f.write(raw_output)\n",
    "print(f\"[INFO] Raw Gemini output saved → {RAW_TXT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a0556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Parsed report JSON saved → ../ai_report/report.json\n",
      "[INFO] Markdown report saved → ../ai_report/report.md\n",
      "\n",
      "Gemini analysis complete! Open:\n",
      "- JSON: ../ai_report/report.json\n",
      "- Markdown: ../ai_report/report.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ws/_w9xx6h56d3cx9mj09tdwf7h0000gn/T/ipykernel_85492/3131767328.py:24: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Robust JSON parsing\"\"\"\n",
    "def parse_json(text: str):\n",
    "    # Try direct JSON\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Try to extract the largest {...} block\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1 and end > start:\n",
    "        try:\n",
    "            return json.loads(text[start:end+1])\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "parsed = parse_json(raw_output)\n",
    "with open(REPORT_JSON_PATH, \"w\") as f:\n",
    "    json.dump(parsed, f, indent=2)\n",
    "print(f\"[INFO] Parsed report JSON saved → {REPORT_JSON_PATH}\")\n",
    "\n",
    "# --- 8) Render Markdown report ---\n",
    "def render_md(report: dict) -> str:\n",
    "    now = datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "    lines = []\n",
    "    lines.append(f\"# AI Analysis Report — Gemini 2.0 Flash\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"_Generated: {now}_\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(f\"**Project:** {report.get('project_title','(unknown)')}  \")\n",
    "    lines.append(f\"**Schema:** {report.get('schema_version','?')}\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    per_ds = report.get(\"per_dataset\", {})\n",
    "    for ds, block in per_ds.items():\n",
    "        lines.append(f\"## Dataset: {ds}\")\n",
    "        lines.append(\"\")\n",
    "        # Best detectors\n",
    "        lines.append(\"### Best Detectors\")\n",
    "        bds = block.get(\"best_detectors\", [])\n",
    "        if bds:\n",
    "            for item in bds:\n",
    "                method = item.get(\"method\",\"?\")\n",
    "                reason = item.get(\"reason\",\"\")\n",
    "                nums = item.get(\"supporting_numbers\",{})\n",
    "                lines.append(f\"- **{method}** — {reason}  \\n  Numbers: `{json.dumps(nums)}`\")\n",
    "        else:\n",
    "            lines.append(\"- _(none reported)_\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        # Hypotheses\n",
    "        lines.append(\"### Hypotheses\")\n",
    "        hyps = block.get(\"hypothesis\", [])\n",
    "        if hyps:\n",
    "            for i, h in enumerate(hyps, 1):\n",
    "                lines.append(f\"{i}. {h}\")\n",
    "        else:\n",
    "            lines.append(\"- _(none reported)_\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        # Numerical patterns\n",
    "        lines.append(\"### Numerical Patterns\")\n",
    "        pats = block.get(\"numerical_patterns\", [])\n",
    "        if pats:\n",
    "            for p in pats:\n",
    "                lines.append(f\"- {p}\")\n",
    "        else:\n",
    "            lines.append(\"- _(none reported)_\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "        # Notes\n",
    "        notes = block.get(\"notes\",\"\").strip()\n",
    "        if notes:\n",
    "            lines.append(\"### Notes\")\n",
    "            lines.append(notes)\n",
    "            lines.append(\"\")\n",
    "\n",
    "    # Cross-sensor\n",
    "    lines.append(\"## Cross-Sensor Insights\")\n",
    "    csi = report.get(\"cross_sensor_insights\", [])\n",
    "    if csi:\n",
    "        for p in csi:\n",
    "            lines.append(f\"- {p}\")\n",
    "    else:\n",
    "        lines.append(\"- _(none reported)_\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Industrial relevance\n",
    "    lines.append(\"## Industrial Relevance Insights\")\n",
    "    iri = report.get(\"industrial_relevance_insights\", [])\n",
    "    if iri:\n",
    "        for p in iri:\n",
    "            lines.append(f\"- {p}\")\n",
    "    else:\n",
    "        lines.append(\"- _(none reported)_\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "    # Final summary\n",
    "    lines.append(\"## General Final Summary\")\n",
    "    lines.append(report.get(\"general_final_summary\",\"(none)\"))\n",
    "    lines.append(\"\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "report_md = render_md(parsed)\n",
    "\n",
    "with open(REPORT_MD_PATH, \"w\") as f:\n",
    "    f.write(report_md)\n",
    "print(f\"[INFO] Markdown report saved → {REPORT_MD_PATH}\")\n",
    "\n",
    "print(\"\\nGemini analysis complete! Open:\")\n",
    "print(f\"- JSON: {REPORT_JSON_PATH}\")\n",
    "print(f\"- Markdown: {REPORT_MD_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
